# Backend configuration
backend:
  image: genet-backend:latest
  imagePullPolicy: IfNotPresent
  replicas: 2

  # 节点选择器（K8s 原生格式）
  # 用于将 Genet 后端调度到特定节点
  nodeSelector: {}
  # 示例:
  #   kubernetes.io/os: linux
  #   node-role: management

  # 亲和性调度（K8s 原生格式）
  affinity: {}
  # 示例 - 节点亲和性（优先调度到特定节点）:
  #   nodeAffinity:
  #     preferredDuringSchedulingIgnoredDuringExecution:
  #       - weight: 100
  #         preference:
  #           matchExpressions:
  #             - key: node-role
  #               operator: In
  #               values:
  #                 - management
  # 示例 - Pod 反亲和性（分散部署到不同节点）:
  #   podAntiAffinity:
  #     preferredDuringSchedulingIgnoredDuringExecution:
  #       - weight: 100
  #         podAffinityTerm:
  #           labelSelector:
  #             matchLabels:
  #               app: genet-backend
  #           topologyKey: kubernetes.io/hostname

  # 容忍度（K8s 原生格式）
  # 用于调度到带有 taint 的节点
  tolerations: []
  # 示例:
  #   - key: "node-role"
  #     operator: "Equal"
  #     value: "management"
  #     effect: "NoSchedule"

  # Backend configuration (injected via ConfigMap)
  config:
    podLimitPerUser: 5
    gpuLimitPerUser: 8

    gpu:
      availableTypes:
        - name: "NVIDIA A100"
          resourceName: "nvidia.com/gpu"
          nodeSelector:
            gpu-type: "a100"
        - name: "NVIDIA V100"
          resourceName: "nvidia.com/gpu"
          nodeSelector:
            gpu-type: "v100"
        - name: "NVIDIA T4"
          resourceName: "nvidia.com/gpu"
          nodeSelector:
            gpu-type: "t4"

      presetImages:
        - name: "CUDA 12.0"
          image: "nvidia/cuda:12.0.0-base-ubuntu22.04"
          description: "NVIDIA CUDA 12.0 基础镜像"
        - name: "PyTorch 2.0"
          image: "pytorch/pytorch:2.0.1-cuda11.7-cudnn8-runtime"
          description: "PyTorch 2.0 with CUDA 11.7"
        - name: "TensorFlow 2.13"
          image: "tensorflow/tensorflow:2.13.0-gpu"
          description: "TensorFlow 2.13 GPU 版本"

    ui:
      enableJupyter: false
      enableCustomImage: true
      # CPU 和内存选项配置
      cpuOptions:
        - "2"
        - "4"
        - "8"
        - "16"
      memoryOptions:
        - "4Gi"
        - "8Gi"
        - "16Gi"
        - "32Gi"
        - "64Gi"
      defaultCPU: "4"
      defaultMemory: "8Gi"

    lifecycle:
      # 每日自动删除所有 Pod 的时间
      autoDeleteTime: "23:00"
      timezone: "Asia/Shanghai"

    storage:
      # 用户 workspace PVC 配置
      storageClass: "standard" # 根据集群调整
      size: "50Gi"
      # PVC 访问模式
      # - ReadWriteOnce (RWO): 单节点读写，适用于大多数存储
      # - ReadWriteMany (RWX): 多节点读写，需要支持的存储（如 NFS、CephFS）
      # - ReadOnlyMany (ROX): 多节点只读
      # - ReadWriteOncePod (RWOP): 单 Pod 读写（K8s 1.22+）
      accessMode: "ReadWriteOnce"

      # 注意：extraVolumes 已废弃，请使用下面的 pod.extraVolumes（K8s 原生格式）
      # extraVolumes: []

    # Pod 配置（Kubernetes 原生格式）
    # 使用 K8s 标准 YAML，直接参考 K8s 官方文档配置
    # 文档: https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.23/#podspec-v1-core
    pod:
      # 使用主机网络
      hostNetwork: true

      # DNS 策略（K8s 原生格式）
      # 可选值: ClusterFirst, ClusterFirstWithHostNet, Default, None
      # 当 hostNetwork=true 时，推荐使用 ClusterFirstWithHostNet（默认值）
      dnsPolicy: ClusterFirstWithHostNet

      # 自定义 DNS 配置（可选，当 dnsPolicy 为 None 时必须配置）
      # dnsConfig:
      #   nameservers:
      #     - 8.8.8.8
      #     - 8.8.4.4
      #   searches:
      #     - cluster.local
      #   options:
      #     - name: ndots
      #       value: "5"

      # 资源配置由用户在 UI 上自定义选择（CPU 和内存）
      # 预设选项在 ui.cpuOptions 和 ui.memoryOptions 中配置

      # 安全上下文（K8s 原生格式）
      securityContext:
        capabilities:
          add:
            - SYS_ADMIN

      # 节点选择器（标签匹配，可选）
      # nodeSelector:
      #   disk: ssd
      #   env: production

      # 亲和性调度（高级规则，K8s 原生格式，可选）
      # 文档: https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#affinity-and-anti-affinity
      # affinity:
      #   nodeAffinity:
      #     # 必须满足的规则（硬约束）
      #     requiredDuringSchedulingIgnoredDuringExecution:
      #       nodeSelectorTerms:
      #         - matchExpressions:
      #             - key: nvidia.com/gpu
      #               operator: Exists
      #     # 优先满足的规则（软约束）
      #     preferredDuringSchedulingIgnoredDuringExecution:
      #       - weight: 80  # 权重 1-100
      #         preference:
      #           matchExpressions:
      #             - key: disk
      #               operator: In
      #               values:
      #                 - ssd
      #                 - nvme
      #       - weight: 50
      #         preference:
      #           matchExpressions:
      #             - key: topology.kubernetes.io/region
      #               operator: In
      #               values:
      #                 - us-west-1
      #                 - us-west-2

      # 额外的存储配置（K8s 原生格式，可选）
      # 注意：用户的 workspace PVC 会自动添加，这里配置额外的存储卷
      # 文档: https://kubernetes.io/docs/concepts/storage/volumes/
      # extraVolumes: []
      # extraVolumeMounts: []
      # 示例配置：
      # extraVolumes:
      #   # PVC 存储（共享数据集）
      #   - name: datasets
      #     persistentVolumeClaim:
      #       claimName: shared-datasets
      #       readOnly: true
      #   # HostPath 存储（本地缓存）
      #   - name: cache
      #     hostPath:
      #       path: /mnt/cache
      #       type: DirectoryOrCreate
      #   # NFS 存储（网络存储）
      #   - name: models
      #     nfs:
      #       server: nfs.example.com
      #       path: /exports/models
      #       readOnly: true
      #   # ConfigMap（配置文件）
      #   - name: config
      #     configMap:
      #       name: my-config
      #   # Secret（密钥）
      #   - name: credentials
      #     secret:
      #       secretName: my-secret
      # extraVolumeMounts:
      #   - name: datasets
      #     mountPath: /data/datasets
      #     readOnly: true
      #   - name: cache
      #     mountPath: /data/cache
      #   - name: models
      #     mountPath: /data/models
      #     readOnly: true
      #   - name: config
      #     mountPath: /etc/config
      #     readOnly: true
      #   - name: credentials
      #     mountPath: /etc/credentials
      #     readOnly: true

      # 容器启动脚本模板
      # 可用变量: {{.ProxyScript}}
      startupScript: |
        #!/bin/bash
        set -e

        echo "=== Starting Genet Pod ==="

        # 创建必要目录
        mkdir -p /workspace

        # 持久化 VS Code Server 目录（避免每次连接重新下载）
        mkdir -p /workspace/.vscode-server
        rm -rf /root/.vscode-server 2>/dev/null || true
        ln -sf /workspace/.vscode-server /root/.vscode-server
        echo "VS Code Server directory linked to /workspace/.vscode-server"

        {{.ProxyScript}}

        # 显示 GPU 信息（如果有）
        if command -v nvidia-smi &> /dev/null; then
            echo "===== GPU Information ====="
            nvidia-smi || true
        else
            echo "===== CPU Only Mode ====="
        fi

        echo ""
        echo "============================================"
        echo "Pod is ready!"
        echo "Use VSCode Kubernetes plugin to attach."
        echo "============================================"

        # 保持容器运行
        tail -f /dev/null

    oauth:
      enabled: false
      # 认证模式: "oidc" 或 "oauth"
      # - oidc: 自动发现端点（需配置 providerURL）
      # - oauth: 手动配置端点（需配置 authorizationEndpoint, tokenEndpoint）
      mode: "oidc"

      # OIDC 模式配置
      providerURL: "" # OIDC Issuer URL，如: https://auth.example.com

      # OAuth 模式配置（mode 为 "oauth" 时使用）
      authorizationEndpoint: "" # OAuth 授权端点
      tokenEndpoint: "" # OAuth Token 端点
      userinfoEndpoint: "" # 用户信息端点（可选）

      # 用户信息获取方式: "endpoint", "token", "both"
      # - endpoint: 从 userinfo API 获取
      # - token: 从 access_token/id_token JWT 解析
      # - both: 优先从 token 解析，失败则调用 endpoint
      userinfoSource: "endpoint"

      # userinfo API 的请求方式: "get" 或 "post"
      # - get:  GET 请求 + Authorization: Bearer {token} （标准 OIDC）
      # - post: POST JSON 请求，body 包含 {client_id, access_token, scope}
      userinfoMethod: "get"

      # 用户信息字段映射（适用于 token 解析和 endpoint 响应）
      tokenUsernameClaim: "preferred_username" # 用户名字段
      tokenEmailClaim: "email" # 邮箱字段

      # 公共配置
      clientID: ""
      clientSecret: ""
      redirectURL: "" # 如: https://genet.example.com/api/auth/callback
      frontendURL: "" # 如: https://genet.example.com
      scopes:
        - "openid"
        - "profile"
        - "email"
      jwtSecret: "" # 生产环境必须设置强密钥
      cookieDomain: ""
      cookieSecure: true # 生产环境使用 HTTPS

    # ============================================
    # OIDC Provider 配置（Genet 作为 OIDC Provider）
    # ============================================
    # 启用后，Genet 会作为 OIDC Provider，将企业 OAuth 转换为标准 OIDC
    # K8s API Server 可以直接信任 Genet，用户可以使用 kubectl 访问集群
    oidcProvider:
      enabled: false
      # Issuer URL，必须是外部可访问的地址
      # 例如: https://genet.example.com
      issuerURL: ""
      # RSA 密钥（用于签名 JWT，生产环境应配置固定密钥）
      # 如果留空，会自动生成（但重启后已签发的 Token 会失效）
      rsaPrivateKey: ""
      rsaPublicKey: ""
      # Kubernetes 客户端配置
      kubernetesClientID: "kubernetes"
      kubernetesClientSecret: ""

    # ============================================
    # K8s 集群配置（用于生成 kubeconfig）
    # ============================================
    cluster:
      name: "" # 集群名称，如: my-cluster
      server: "" # K8s API Server 地址，如: https://k8s-api.example.com:6443
      caData: "" # CA 证书（base64 编码）

    # ============================================
    # 用户 RBAC 配置
    # ============================================
    userRBAC:
      enabled: false # 是否启用用户 RBAC 管理
      autoCreate: true # 登录时自动创建用户 Namespace 和 RBAC

    # 代理配置（会注入到用户 Pod 的环境变量和 ~/.bashrc 中）
    proxy:
      httpProxy: "" # HTTP 代理地址，如: http://proxy.example.com:8080
      httpsProxy: "" # HTTPS 代理地址
      noProxy: "localhost,127.0.0.1,.cluster.local,10.0.0.0/8" # 不使用代理的地址

    # 镜像仓库配置（用于镜像保存/commit 功能）
    registry:
      url: "" # 镜像仓库地址，如: registry.example.com
      username: "" # 仓库用户名
      password: "" # 仓库密码

    # 系统依赖镜像配置
    images:
      nerdctl: "ghcr.io/containerd/nerdctl:v1.7.0" # nerdctl 镜像，用于 commit 操作

    # Kubernetes 客户端配置
    kubernetes:
      disableProxy: true # 禁用 HTTP/HTTPS 代理（解决 Windows 代理冲突）
      timeout: 30 # API 请求超时时间（秒）

# Frontend configuration
frontend:
  image: genet-frontend:latest
  imagePullPolicy: IfNotPresent
  replicas: 2

  # 节点选择器（K8s 原生格式）
  nodeSelector: {}

  # 亲和性调度（K8s 原生格式）
  affinity: {}

  # 容忍度（K8s 原生格式）
  tolerations: []

# CronJob configuration (pod cleanup)
cleanup:
  # 每天 23:00 执行清理（删除所有用户 Pod）
  schedule: "0 23 * * *"
  image: genet-backend:latest

# Ingress configuration
ingress:
  enabled: true
  className: "nginx"
  host: "genet.example.com"

  # 额外的 Ingress 注解
  annotations: {}
    # nginx.ingress.kubernetes.io/proxy-body-size: "100m"
    # nginx.ingress.kubernetes.io/proxy-read-timeout: "3600"

  # TLS 配置
  tls:
    enabled: false
    # 证书 Secret 名称（如果使用 cert-manager，可留空自动生成）
    secretName: ""

  # cert-manager 配置（自动申请 TLS 证书）
  certManager:
    enabled: false
    # 使用 ClusterIssuer（集群级别）
    clusterIssuer: "" # 如: "letsencrypt-prod"
    # 或使用 Issuer（Namespace 级别）
    issuer: "" # 如: "letsencrypt-staging"

# Service configuration
service:
  backend:
    type: ClusterIP
    port: 8080
  frontend:
    type: ClusterIP
    port: 80

# ============================================
# cert-manager 配置（可选，用于自动申请 TLS 证书）
# ============================================
# 前提：需要先安装 cert-manager
# kubectl apply -f https://github.com/cert-manager/cert-manager/releases/download/v1.13.0/cert-manager.yaml
certManager:
  # 是否创建 ClusterIssuer（如果已有可设为 false）
  createClusterIssuer: false

  # 证书类型: "selfsigned" 或 "acme"
  # - selfsigned: 自签名证书（内网环境推荐）
  # - acme: Let's Encrypt 证书（公网环境）
  type: "selfsigned"

  # ClusterIssuer 名称
  # selfsigned 模式: 默认 "selfsigned-issuer"，实际签发使用 "genet-ca-issuer"
  # acme 模式: 默认 "letsencrypt-prod"
  clusterIssuerName: "selfsigned-issuer"

  # ============================================
  # ACME 模式配置（type: "acme" 时使用）
  # ============================================
  # ACME 服务器地址
  # 生产环境: https://acme-v02.api.letsencrypt.org/directory
  # 测试环境: https://acme-staging-v02.api.letsencrypt.org/directory
  acmeServer: "https://acme-v02.api.letsencrypt.org/directory"
  # 接收证书过期通知的邮箱（ACME 模式必填）
  email: ""
  # DNS-01 验证配置（可选，用于通配符证书）
  # 如果不配置，默认使用 HTTP-01 验证
  # dns01:
  #   cloudflare:
  #     apiTokenSecretRef:
  #       name: cloudflare-api-token
  #       key: api-token
