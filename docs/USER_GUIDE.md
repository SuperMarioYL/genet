# Genet 使用指南

## 为什么团队需要 Genet？

### 痛点分析

在 AI/ML 团队日常工作中，GPU 资源管理往往面临以下挑战：

| 痛点 | 传统方式 | Genet 解决方案 |
|------|---------|---------------|
| **资源争抢** | 多人共用服务器，互相影响 | 每人独立 Pod，环境隔离 |
| **环境污染** | 依赖冲突，cuda 版本混乱 | 容器化环境，随时重建 |
| **GPU 闲置** | 独占卡但利用率低 | 共享模式，提升整体利用率 |
| **配置繁琐** | 手动配 SSH、端口、存储 | 一键创建，自动配置 |
| **资源不透明** | 不知道谁占用了哪张卡 | 热力图实时可视化 |

### Genet 核心价值

```
┌─────────────────────────────────────────────────────────┐
│                    Genet 平台                           │
├─────────────────────────────────────────────────────────┤
│  ✓ 自助式 GPU Pod 创建        ✓ SSH / VSCode 远程连接   │
│  ✓ 持久化存储自动挂载         ✓ 镜像保存与复用          │
│  ✓ GPU 利用率实时监控         ✓ 资源配额管理            │
│  ✓ 支持 NVIDIA GPU / 华为昇腾  ✓ 共享模式提升利用率     │
└─────────────────────────────────────────────────────────┘
```

---

## 快速开始

### 1. 登录平台

访问平台地址（由管理员提供），使用企业账号登录。

<!-- 截图位置：登录页面 -->
> **[截图]** 登录页面

---

### 2. 查看 GPU 资源概览

登录后，首页展示集群 GPU 资源热力图：

- **绿色** → 空闲/低负载
- **黄色** → 中等负载
- **红色** → 高负载/已满

<!-- 截图位置：GPU 热力图概览 -->
> **[截图]** GPU 热力图 - 可以看到每张卡的利用率、显存、占用者

悬浮在卡片上可查看详细信息：
- SM 利用率
- 显存使用量
- 当前占用的 Pod

---

### 3. 创建 Pod

点击 **「创建 Pod」** 按钮，打开创建对话框。

#### 3.1 基础配置

| 配置项 | 说明 | 建议值 |
|-------|------|-------|
| **基础镜像** | 预装环境的容器镜像 | 根据项目选择 |
| **Pod 名称** | 自定义名称（可选） | 如 `train`, `dev` |
| **CPU 核数** | 分配的 CPU 资源 | 4-8 核 |
| **内存大小** | 分配的内存 | 8-32 Gi |
| **GPU 类型** | NVIDIA / 昇腾 | 按需选择 |

<!-- 截图位置：创建 Pod 对话框 - 左侧基础配置 -->
> **[截图]** 创建 Pod - 基础配置区域

#### 3.2 选择节点和 GPU 卡（共享模式）

在共享模式下，需要手动选择节点和 GPU 卡：

1. **选择节点** - 下拉框会根据 GPU 类型自动过滤
2. **选择 GPU 卡** - 点击卡片选择，支持多选

<!-- 截图位置：创建 Pod 对话框 - 右侧 GPU 选择 -->
> **[截图]** 创建 Pod - GPU 卡选择区域（热力图风格）

**选择技巧：**
- 优先选择绿色（低负载）的卡
- 按住 `Shift` 可范围选择多张卡
- 悬浮查看卡的详细占用情况

#### 3.3 配额检查

创建前会显示配额使用预览：

<!-- 截图位置：配额预览区域 -->
> **[截图]** 配额预览 - 显示 Pod 和 GPU 使用量

---

### 4. 管理 Pod

#### 4.1 Pod 列表

创建成功后，在首页可以看到你的所有 Pod：

<!-- 截图位置：Pod 卡片列表 -->
> **[截图]** Pod 列表 - 显示状态、资源、连接方式

**Pod 状态说明：**

| 状态 | 含义 |
|-----|------|
| 🟢 Running | 运行中，可正常使用 |
| 🟡 Pending | 等待调度中 |
| 🔴 Failed | 启动失败 |
| ⚪ Terminating | 正在删除 |

#### 4.2 连接 Pod

**方式一：SSH 命令行**

```bash
# 复制 Pod 卡片上的 SSH 命令
ssh -p <端口> root@<节点IP>
```

**方式二：VSCode Remote**

1. 安装 VSCode Remote-SSH 扩展
2. 点击 Pod 卡片上的 **「VSCode」** 按钮
3. 自动打开 VSCode 并连接

<!-- 截图位置：VSCode 连接按钮 -->
> **[截图]** Pod 卡片 - 连接按钮区域

**方式三：下载 Kubeconfig**

点击 **「Kubeconfig」** 下载配置文件，可使用 `kubectl` 直接操作：

```bash
export KUBECONFIG=~/Downloads/kubeconfig-xxx.yaml
kubectl exec -it <pod-name> -- /bin/bash
```

---

### 5. 保存镜像

完成环境配置后，可以将当前 Pod 保存为镜像，方便复用：

1. 点击 Pod 卡片上的 **「保存镜像」** 按钮
2. 输入镜像名称和标签
3. 等待保存完成

<!-- 截图位置：保存镜像对话框 -->
> **[截图]** 保存镜像对话框

**保存后的镜像会出现在「基础镜像」下拉列表中，下次创建 Pod 可直接选用。**

---

### 6. 延长 Pod 生命周期

默认情况下，Pod 会在每晚 23:00 自动清理。如需保留：

1. 点击 **「延长」** 按钮
2. 选择延长时间

<!-- 截图位置：延长 Pod 按钮 -->
> **[截图]** 延长 Pod 生命周期

---

## 最佳实践

### 环境管理

```
推荐工作流：

1. 基于预设镜像创建 Pod
2. 安装项目依赖、配置环境
3. 保存为个人镜像
4. 后续直接使用个人镜像创建
```

### GPU 使用建议

| 场景 | 建议 |
|-----|------|
| **调试代码** | 选择 1 张低负载卡 |
| **训练模型** | 根据模型大小选择多卡 |
| **推理服务** | 选择显存充足的卡 |

### 存储说明

每个用户有独立的持久化存储（PVC），挂载在 `/workspace` 目录：

```
/workspace/
├── projects/      # 项目代码
├── datasets/      # 数据集（建议软链接）
└── checkpoints/   # 模型检查点
```

**注意：Pod 删除后 `/workspace` 数据保留，其他目录数据丢失。**

---

## 常见问题

### Q: Pod 一直处于 Pending 状态？

**可能原因：**
1. 集群资源不足，等待其他 Pod 释放
2. 所选节点资源已满

**解决方案：**
- 查看热力图，选择负载较低的节点/卡
- 减少 CPU/内存请求量
- 联系管理员扩容

### Q: 无法 SSH 连接？

**排查步骤：**
1. 确认 Pod 状态为 Running
2. 检查 SSH 端口是否正确
3. 确认网络可达（VPN 是否连接）

### Q: 如何查看 GPU 使用情况？

在 Pod 内执行：

```bash
# NVIDIA GPU
nvidia-smi

# 华为昇腾
npu-smi info
```

### Q: 镜像保存失败？

**可能原因：**
1. 镜像仓库空间不足
2. 网络连接问题
3. 镜像名称格式错误

**建议：** 联系管理员检查镜像仓库状态。

---

## 联系支持

如有问题，请联系平台管理员或在内部群组反馈。

<!-- 可补充：管理员联系方式、反馈渠道等 -->
